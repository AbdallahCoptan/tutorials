<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <title>HPC workflow with sequential jobs - UL HPC Tutorials</title>
  

  <link rel="shortcut icon" href="../../img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">

  
  <script>
    // Current page data
    var mkdocs_page_name = "HPC workflow with sequential jobs";
    var mkdocs_page_input_path = "basic/sequential_jobs/index.md";
    var mkdocs_page_url = "/basic/sequential_jobs/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script>
  <script src="../../js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> UL HPC Tutorials</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../..">Home</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Basic Tutorials</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../getting_started/">Getting Started</a>
        
    </li>

        
            
    <li class="toctree-l1 current">
        <a class="current" href="./">HPC workflow with sequential jobs</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#ul-hpc-tutorial-hpc-workflow-with-sequential-jobs">UL HPC Tutorial: HPC workflow with sequential jobs</a></li>
                
                    <li><a class="toctree-l4" href="#introduction">Introduction</a></li>
                
                    <li><a class="toctree-l4" href="#pre-requisites">Pre-requisites</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-1-parametric-experiment-with-gromacs">Exercise 1: Parametric experiment with Gromacs</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-2-watermarking-images-in-python">Exercise 2: Watermarking images in Python</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-3-advanced-use-case-using-a-java-program-jcell">Exercise 3: Advanced use case, using a Java program: "JCell"</a></li>
                
                    <li><a class="toctree-l4" href="#conclusion">Conclusion</a></li>
                
            
            </ul>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Debug/">Efficient Debugging</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Advanced Software Management</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/EasyBuild/">Easybuild</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/RESIF/">RESIF</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>MPI / Performance Evaluation</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/OSU_MicroBenchmarks/">OSU Micro-benchmarks</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/HPL/">High Performance Linpack (HPL)</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/HPCG/">High Performance Conjugate Gradient (HPCG)</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Mathematics</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/MATLAB1/README/">MATLAB</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/R/">R - statistical computing</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Bioinformatics</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Bioinformatics/">Running bioinformatics software</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Galaxy/">Galaxy</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Parallel Debuggers</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Allinea/">Allinea</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/TotalView/">TotalView</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Virtualization</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Vagrant/">Vagrant</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/vm5k/">Grid5000 - Automatic VM deployment with VM5K</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>CFD/MD/Chemistry</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/MultiPhysics/">Advanced Parallel execution</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Big Data</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Spark/">Big Data Application Over Apache Spark</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Advanced topics</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/advanced_workflows/README/">Advanced workflows on sequential jobs management</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/advanced_scheduling/">Advanced scheduling with SLURM</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/Python/">Prototyping with Python</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../advanced/ReproducibleResearch/">Reproducible Research</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../rtfd/">Documentation (RTFD)</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../contributing/">Contributing</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../contacts/">Contacts</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">UL HPC Tutorials</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Basic Tutorials &raquo;</li>
        
      
    
    <li>HPC workflow with sequential jobs</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p>-<em>- mode: markdown; mode: auto-fill; fill-column: 80 -</em>-</p>
<p>Copyright (c) 2016-2017 <a href="mailto:&lt;hpc-sysadmins@uni.lu&gt;">ULHPC management team</a> --  <a href="http://hpc.uni.lu">www</a></p>
<hr />
<h1 id="ul-hpc-tutorial-hpc-workflow-with-sequential-jobs">UL HPC Tutorial: HPC workflow with sequential jobs</h1>
<p><a href="https://hpc.uni.lu"><img alt="By ULHPC" src="https://img.shields.io/badge/by-ULHPC-blue.svg" /></a> <a href="http://www.gnu.org/licenses/gpl-3.0.html"><img alt="Licence" src="https://img.shields.io/badge/license-GPL--3.0-blue.svg" /></a> <a href="https://github.com/ULHPC/tutorials/issues/"><img alt="GitHub issues" src="https://img.shields.io/github/issues/ULHPC/tutorials.svg" /></a> <a href="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/slides.pdf"><img alt="" src="https://img.shields.io/badge/slides-PDF-red.svg" /></a> <a href="https://github.com/ULHPC/tutorials/tree/devel/basic/sequential_jobs/"><img alt="Github" src="https://img.shields.io/badge/sources-github-green.svg" /></a> <a href="http://ulhpc-tutorials.readthedocs.io/en/latest/basic/sequential_jobs/"><img alt="Documentation Status" src="http://readthedocs.org/projects/ulhpc-tutorials/badge/?version=latest" /></a> <a href="https://github.com/ULHPC/tutorials"><img alt="GitHub forks" src="https://img.shields.io/github/stars/ULHPC/tutorials.svg?style=social&amp;label=Star" /></a></p>
<p><a href="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/slides.pdf"><img alt="" src="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/cover_slides.png" /></a></p>
<p><strong>Prerequisites</strong></p>
<p>Make sure you have followed the tutorial <a href="./../getting_started/">"Getting started"</a>.</p>
<h2 id="introduction">Introduction</h2>
<p>For many users, the typical usage of the HPC facilities is to execute 1 program with many parameters.
On your local machine, you can just start your program 100 times sequentially.
However, you will obtain better results if you parallelize the executions on a HPC Cluster.</p>
<p>During this session, we will see 3 use cases:</p>
<ul>
<li><em>Exercise 1</em>: Use the serial launcher (1 node, in sequential and parallel mode);</li>
<li><em>Exercise 2</em>: Use the generic launcher, distribute your executions on several nodes (python script);</li>
<li><em>Exercise 3</em>: Advanced use case, using a Java program: "JCell".</li>
</ul>
<p>We will use the following github repositories:</p>
<ul>
<li><a href="https://github.com/ULHPC/launcher-scripts">ULHPC/launcher-scripts</a></li>
<li><a href="https://github.com/ULHPC/tutorials">ULHPC/tutorials</a></li>
</ul>
<h2 id="pre-requisites">Pre-requisites</h2>
<h3 id="connect-to-the-cluster-access-node-and-set-up-the-environment-for-this-tutorial">Connect to the cluster access node, and set-up the environment for this tutorial</h3>
<p>You can chose one of the 3 production cluster hosted by the University of Luxembourg.</p>
<p>For the next sections, note that you will use <code>Slurm</code> on Iris, and <code>OAR</code> on Chaos &amp; Gaia.</p>
<pre><code class="bash">(yourmachine)$&gt; ssh iris-cluster
(yourmachine)$&gt; ssh chaos-cluster
(yourmachine)$&gt; ssh gaia-cluster
</code></pre>

<p>If your network connection is unstable, use <a href="http://www.mechanicalkeys.com/files/os/notes/tm.html">screen</a>:</p>
<pre><code class="bash">(access)$&gt; screen
</code></pre>

<p>We will work in <a href="https://hpc.uni.lu/users/docs/env.html#working-directories">the home directory</a>.</p>
<p>You can check the usage of your directories using the command <code>df-ulhpc</code> on Gaia</p>
<pre><code class="bash">(access)$&gt; df-ulhpc
Directory                         Used  Soft quota  Hard quota  Grace period
---------                         ----  ----------  ----------  ------------
/home/users/hcartiaux             3.2G  100G        -           none
/work/users/hcartiaux             39M   3.0T        -           none
</code></pre>

<p>Note that the user directories are not yet all available on Iris, and that the quota are not yet enabled.</p>
<p>Create a sub directory $HOME/PS2, and work inside it</p>
<pre><code class="bash">(access)$&gt; mkdir $HOME/PS2
(access)$&gt; cd $HOME/PS2
</code></pre>

<p>In the following parts, we will assume that you are working in this directory.</p>
<p>Clone the repositories <code>ULHPC/tutorials</code> and <code>ULHPC/launcher-scripts.git</code></p>
<pre><code>(access)$&gt; git clone https://github.com/ULHPC/launcher-scripts.git
(access)$&gt; git clone https://github.com/ULHPC/tutorials.git
</code></pre>
<p>In order to edit files in your terminal, you are expected to use your preferred text editor:</p>
<ul>
<li><a href="http://www.howtogeek.com/howto/42980/the-beginners-guide-to-nano-the-linux-command-line-text-editor/">nano</a></li>
<li><a href="http://vimdoc.sourceforge.net/htmldoc/usr_toc.html">vim</a></li>
<li><a href="http://www.jesshamrick.com/2012/09/10/absolute-beginners-guide-to-emacs/">emacs</a></li>
<li>...</li>
</ul>
<p>If you have never used any of them, <code>nano</code> is intuitive, but vim and emacs are more powerful.</p>
<h2 id="exercise-1-parametric-experiment-with-gromacs">Exercise 1: Parametric experiment with Gromacs</h2>
<p>Gromacs is a popular molecular dynamics software.
In this exercise, we will process some example input files, and make the parameter <code>fourier_spacing</code> varies from 0.1 to 0.2 in increments of 0.005.</p>
<p>Create a file which contains the list of parameters:</p>
<pre><code>(access)$&gt; seq 0.1 0.002 0.2 &gt; $HOME/PS2/param_file
</code></pre>
<h4 id="step-1-naive-workflow">Step 1: Naive workflow</h4>
<p>We will use the launcher <code>NAIVE_AKA_BAD_launcher_serial.sh</code> (full path: <code>$HOME/PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh</code>).</p>
<p>Edit the following variables:</p>
<ul>
<li><code>MODULE_TO_LOAD</code> must contain the list of modules to load before executing <code>$TASK</code>,</li>
<li><code>TASK</code> must contain the path of the executable,</li>
<li><code>ARG_TASK_FILE</code> must contain the path of your parameter file.<pre><code>(node)$&gt; nano $HOME/PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh

    MODULE_TO_LOAD=(bio/GROMACS)
    TASK="$HOME/PS2/tutorials/basic/sequential_jobs/scripts/run_gromacs_sim.sh"
    ARG_TASK_FILE=$HOME/PS2/param_file
</code></pre>
</li>
</ul>
<h5 id="step-1a-using-oar-on-chaos-gaia">Step 1a: using OAR on Chaos &amp; Gaia</h5>
<p>Launch the job, in interactive mode and execute the launcher:</p>
<pre><code>(access)$&gt; oarsub -I -l core=1

    [ADMISSION RULE] Set default walltime to 7200.
    [ADMISSION RULE] Modify resource description with type constraints
    OAR_JOB_ID=1542591
    Interactive mode : waiting...
    Starting...

    Connect to OAR job 1542591 via the node d-cluster1-1
    Linux d-cluster1-1 3.2.0-4-amd64 unknown
     14:27:19 up 29 days, 10 min,  1 user,  load average: 0.00, 0.00, 0.06
    [OAR] OAR_JOB_ID=1542591
    [OAR] Your nodes are:
          d-cluster1-1*1


(node)$ $HOME/PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh
</code></pre>
<p><strong>Or</strong> in passive mode (the output will be written in a file named <code>OAR.&lt;JOBID&gt;.stdout</code>)</p>
<pre><code>(access)$&gt; oarsub -l core=1 $HOME/PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh

    [ADMISSION RULE] Set default walltime to 7200.
    [ADMISSION RULE] Modify resource description with type constraints
    OAR_JOB_ID=1542592
</code></pre>
<p>You can use the command <code>oarstat -f -j &lt;JOBID&gt;</code> to read all the details about your job:</p>
<pre><code>(access)$&gt; oarstat -f -j 1542592
    Job_Id: 1542592
        project = default
        owner = hcartiaux
        state = Running
        wanted_resources = -l "{type = 'default'}/core=1,walltime=2:0:0"
        assigned_resources = 434
        assigned_hostnames = d-cluster1-1
        queue = default
        command = /work/users/hcartiaux//PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh
        ...
</code></pre>
<p>In all cases, you can connect to a reserved node using the command <code>oarsub -C &lt;JOBID&gt;</code>
and check the status of the system using standard linux command (<code>free</code>, <code>top</code>, <code>htop</code>, etc)</p>
<pre><code>$ (access)$&gt; oarsub -C 1542592
    Connect to OAR job 1542592 via the node d-cluster1-1
    Linux d-cluster1-1 3.2.0-4-amd64 unknown
     14:51:56 up 29 days, 35 min,  2 users,  load average: 1.57, 0.98, 0.70
    [OAR] OAR_JOB_ID=1542592
    [OAR] Your nodes are:
          d-cluster1-1*1

0 14:51:57 hcartiaux@d-cluster1-1(chaos-cluster)[OAR1542592-&gt;119] ~ $ free -m
             total       used       free     shared    buffers     cached
Mem:         48393      41830       6563          0        204      25120
-/+ buffers/cache:      16505      31888
Swap:         4095         47       4048
0 14:51:59 hcartiaux@d-cluster1-1(chaos-cluster)[OAR1542592-&gt;119] ~ $ htop
</code></pre>
<p><img alt="Htop screenshot" src="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/images/chaos_htop.png" /></p>
<p>During the execution, you can try to locate your job on the <a href="https://hpc.uni.lu/chaos/monika">monika web interface</a>.</p>
<p><img alt="Monika screenshot" src="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/images/chaos_monika.png" /></p>
<p>Using the <a href="https://hpc.uni.lu/chaos/ganglia">system monitoring tool ganglia</a>, check the activity on your node.</p>
<h5 id="step-1b-using-slurm-on-iris">Step 1b: using Slurm on Iris</h5>
<p>Launch the job, in interactive mode and execute the launcher:</p>
<pre><code>(access)$&gt; srun -p interactive -N 1 --qos qos-interactive --pty bash -i

(node)$ $HOME/PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh
</code></pre>
<p><strong>Or</strong> in passive mode (the output will be written in a file named <code>BADSerial-&lt;JOBID&gt;.out</code>)</p>
<pre><code>(access)$&gt; sbatch $HOME/PS2/launcher-scripts/bash/serial/NAIVE_AKA_BAD_launcher_serial.sh
</code></pre>
<p>You can use the command <code>scontrol show job &lt;JOBID&gt;</code> to read all the details about your job:</p>
<pre><code>(access)$&gt; scontrol show job 2124
JobId=2124 JobName=BADSerial
   UserId=hcartiaux(5079) GroupId=clusterusers(666) MCS_label=N/A
   Priority=100 Nice=0 Account=ulhpc QOS=qos-batch
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:58 TimeLimit=01:00:00 TimeMin=N/
   SubmitTime=2017-06-11T16:12:27 EligibleTime=2017-06-11T16:12:27
   StartTime=2017-06-11T16:12:28 EndTime=2017-06-11T17:12:28 Deadline=N/A
</code></pre>
<p>And the command <code>sacct</code> to see the start and end date</p>
<pre><code>(access)$&gt; sacct --format=start,end --j 2125
              Start                 End
------------------- -------------------
2017-06-11T16:23:23 2017-06-11T16:23:51
2017-06-11T16:23:23 2017-06-11T16:23:51
</code></pre>
<p>In all cases, you can connect to a reserved node using the command <code>srun</code>
and check the status of the system using standard linux command (<code>free</code>, <code>top</code>, <code>htop</code>, etc)</p>
<pre><code>(access)$&gt; srun -p interactive --qos qos-interactive --jobid &lt;JOBID&gt; --pty bash
</code></pre>
<p>During the execution, you can see the job in the queue with the command <code>squeue</code>:</p>
<pre><code>(access)$&gt; squeue
         JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          2124     batch BADSeria hcartiau  R       2:16      1 iris-053
          2122 interacti     bash svarrett  R       5:12      1 iris-081
</code></pre>
<p>Using the <a href="https://hpc.uni.lu/iris/ganglia/">system monitoring tool ganglia</a>, check the activity on your node.</p>
<h4 id="step-2-optimal-method-using-gnu-parallel-gnu-parallel">Step 2: Optimal method using GNU parallel (GNU Parallel)</h4>
<p>We will use the launcher <code>launcher_serial.sh</code> (full path: <code>$HOME/PS2/launcher-scripts/bash/serial/launcher_serial.sh</code>).</p>
<p>Edit the following variables:</p>
<pre><code>(access)$&gt; nano $HOME/PS2/launcher-scripts/bash/serial/launcher_serial.sh

MODULE_TO_LOAD=(bio/GROMACS)
TASK="$HOME/PS2/tutorials/basic/sequential_jobs/scripts/run_gromacs_sim.sh"
ARG_TASK_FILE=$HOME/PS2/param_file
</code></pre>
<p>Submit the (passive) job with <code>oarsub</code> if you are using Chaos or Gaia</p>
<pre><code>(access)$&gt; oarsub -l nodes=1 $HOME/PS2/launcher-scripts/bash/serial/launcher_serial.sh
</code></pre>
<p>Or with <code>sbatch</code> if you are using Iris</p>
<pre><code>(access)$&gt; sbatch $HOME/PS2/launcher-scripts/bash/serial/launcher_serial.sh
</code></pre>
<p><strong>Question</strong>: compare and explain the execution time with both launchers:</p>
<ul>
<li>
<p>Naive workflow: time = <strong>16m 32s</strong>
  <img alt="CPU usage for the sequential workflow" src="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/images/chaos_ganglia_seq.png" /></p>
</li>
<li>
<p>Parallel workflow: time = <strong>2m 11s</strong>
  <img alt="CPU usage for the parallel workflow" src="https://github.com/ULHPC/tutorials/raw/devel/basic/sequential_jobs/images/chaos_ganglia_parallel.png" /></p>
</li>
</ul>
<p><strong>/!\ Gaia and Chaos nodes are heterogeneous. In order to compare execution times,
you must always use the same type of nodes (CPU/Memory), using <a href="https://hpc.uni.lu/users/docs/oar.html#select-nodes-precisely-with-properties">properties</a>
in your <code>oarsub</code> command.</strong></p>
<h2 id="exercise-2-watermarking-images-in-python">Exercise 2: Watermarking images in Python</h2>
<p>We will use another program, <code>watermark.py</code> (full path: <code>$HOME/PS2/tutorials/basic/sequential_jobs/scripts/watermark.py</code>),
and we will distribute the computation on 2 nodes with the launcher <code>parallel_launcher.sh</code>
(full path: <code>$HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh</code>).</p>
<p>This python script will apply a watermark to the images (using the Python Imaging library).</p>
<p>The command works like this:</p>
<pre><code>python watermark.py &lt;path/to/watermark_image&gt; &lt;source_image&gt;
</code></pre>
<p>We will work with 2 files:</p>
<ul>
<li><code>copyright.png</code>: a transparent images, which can be applied as a watermark</li>
<li><code>images.tgz</code>: a compressed file, containing 30 JPG pictures (of the Gaia Cluster :) ).</li>
</ul>
<h4 id="step-0-python-image-manipulation-module-installation">Step 0: python image manipulation module installation</h4>
<p>In an interactive job, install <code>pillow</code> in your home directory using this command:</p>
<pre><code>(access IRIS)&gt;$ srun -p interactive -N 1 --qos qos-interactive --pty bash -i
(access Chaos/Gaia)&gt;$ oarsub -I



(node)&gt;$ pip install --user pillow
</code></pre>
<h4 id="step-1-prepare-the-input-files">Step 1: Prepare the input files</h4>
<p>Copy the source files in your $HOME directory.</p>
<pre><code>(access)&gt;$ tar xvf /mnt/isilon/projects/ulhpc-tutorials/sequential/images.tgz -C $HOME/PS2/
(access)&gt;$ cp /mnt/isilon/projects/ulhpc-tutorials/sequential/copyright.png $HOME/PS2

(access)&gt;$ cd $HOME/PS2
</code></pre>
<h4 id="step-2-create-a-list-of-parameters">Step 2: Create a list of parameters</h4>
<p>We must create a file containing a list of parameters, each line will be passed to <code>watermark.py</code>.</p>
<pre><code>ls -d -1 $HOME/PS2/images/*.JPG | awk -v watermark=$HOME/PS2/copyright.png '{print watermark " " $1}' &gt; $HOME/PS2/generic_launcher_param
\_____________________________/   \_________________________________________________________________/ \_________________________________/
               1                                                    2                                                3
</code></pre>
<ol>
<li><code>ls -d -1</code>: list the images</li>
<li><code>awk ...</code>: prefix each line with the first parameter (watermark file)</li>
<li><code>&gt;</code>: redirect the output to the file $HOME/generic_launcher_param</li>
</ol>
<h4 id="step-3-configure-the-launcher">Step 3: Configure the launcher</h4>
<p>We will use the launcher <code>parallel_launcher.sh</code> (full path: <code>$HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh</code>).</p>
<p>Edit the following variables:</p>
<pre><code>(access)$&gt; nano $HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh

TASK="$HOME/PS2/tutorials/basic/sequential_jobs/scripts/watermark.py"
ARG_TASK_FILE="$HOME/PS2/generic_launcher_param"
# number of cores needed for 1 task
NB_CORE_PER_TASK=2
</code></pre>
<h4 id="step-4-submit-the-job">Step 4: Submit the job</h4>
<p>We will spawn 1 process per 2 cores on 2 nodes</p>
<p>On Iris, the Slurm job submission command is <code>sbatch</code></p>
<pre><code>(access IRIS)&gt;$ sbatch $HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh
</code></pre>
<p>On Chaos and Gaia, the OAR job submission command is <code>oarsub</code></p>
<pre><code>(access Chaos/Gaia)&gt;$ oarsub $HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh
</code></pre>
<h4 id="step-5-download-the-files">Step 5: Download the files</h4>
<p>On your laptop, transfer the files in the current directory and look at them with your favorite viewer.
Use one of these commands according to the cluster you have used:</p>
<pre><code>(yourmachine)$&gt; rsync -avz chaos-cluster:/home/users/&lt;LOGIN&gt;/PS2/images .
(yourmachine)$&gt; rsync -avz gaia-cluster:/home/users/&lt;LOGIN&gt;/PS2/images .
(yourmachine)$&gt; rsync -avz iris-cluster:/home/users/&lt;LOGIN&gt;/PS2/images .
</code></pre>
<p><strong>Question</strong>: which nodes are you using, identify your nodes with the command <code>oarstat -f -j &lt;JOBID&gt;</code> or Monika
(<a href="https://hpc.uni.lu/chaos/monika">Chaos</a>, <a href="https://hpc.uni.lu/gaia/monika">Gaia</a>)</p>
<h2 id="exercise-3-advanced-use-case-using-a-java-program-jcell">Exercise 3: Advanced use case, using a Java program: "JCell"</h2>
<p>Let's use <a href="https://jcell.gforge.uni.lu/">JCell</a>, a framework for working with genetic algorithms, programmed in Java.</p>
<p>We will use 3 scripts:</p>
<ul>
<li><code>jcell_config_gen.sh</code> (full path: <code>$HOME/PS2/tutorials/basic/sequential_jobs/scripts/jcell_config_gen.sh</code>)</li>
</ul>
<p>We want to execute Jcell, and change the parameters MutationProb and CrossoverProb.
This script will install JCell, generate a tarball containing all the configuration files,
and the list of parameters to be given to the launcher.</p>
<ul>
<li><code>jcell_wrapper.sh</code> (full path: <code>$HOME/PS2/tutorials/basic/sequential_jobs/scripts/jcell_wrapper.sh</code>)</li>
</ul>
<p>This script is a wrapper, and will start one execution of jcell with the configuration file given in parameter.
If a result already exists, then the execution will be skipped.
Thanks to this simple test, our workflow is fault tolerant,
if the job is interrupted and restarted, only the missing results will be computed.</p>
<ul>
<li><code>parallel_launcher.sh</code> (full path: <code>$HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh</code>)</li>
</ul>
<p>This script will drive the experiment, start and balance the java processes on all the reserved resources.</p>
<h4 id="step-1-generate-the-configuration-files">Step 1: Generate the configuration files:</h4>
<p>Execute this script:</p>
<pre><code>    (access)$&gt; $HOME/PS2/tutorials/basic/sequential_jobs/scripts/jcell_config_gen.sh
</code></pre>
<p>This script will generate the following files in <code>$HOME/PS2/jcell</code>:</p>
<ul>
<li><code>config.tgz</code></li>
<li><code>jcell_param</code></li>
</ul>
<h4 id="step-2-edit-the-launcher-configuration-in-the-file-homeps2launcher-scriptsbashgenericparallel_launchersh">Step 2: Edit the launcher configuration, in the file <code>$HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh</code>.</h4>
<p>This application is cpu-bound and not memory-bound, so we can set the value of <code>NB_CORE_PER_TASK</code> to 1.
Using these parameters, the launcher will spaw one java process per core on all the reserved nodes.</p>
<pre><code>    (access)$&gt; nano $HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh

    TASK="$HOME/PS2/tutorials/basic/sequential_jobs/scripts/jcell_wrapper.sh"
    ARG_TASK_FILE="$HOME/PS2/jcell/jcell_param"
    # number of cores needed for 1 task
    NB_CORE_PER_TASK=1
</code></pre>
<h4 id="step-3-submit-the-job">Step 3: Submit the job</h4>
<p>On Iris, the Slurm job submission command is <code>sbatch</code></p>
<pre><code>(access IRIS)&gt;$ sbatch $HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh
</code></pre>
<p>On Chaos and Gaia, the OAR job submission command is <code>oarsub</code></p>
<pre><code>(access Chaos/Gaia)&gt;$ oarsub $HOME/PS2/launcher-scripts/bash/generic/parallel_launcher.sh
</code></pre>
<h4 id="step-4-retrieve-the-results-on-your-laptop">Step 4. Retrieve the results on your laptop:</h4>
<p>Use one of these commands according to the cluster you have used:</p>
<pre><code>    (yourmachine)$&gt; rsync -avz chaos-cluster:/home/users/&lt;LOGIN&gt;/PS2/jcell/results .
    (yourmachine)$&gt; rsync -avz gaia-cluster:/home/users/&lt;LOGIN&gt;/PS2/jcell/results .
    (yourmachine)$&gt; rsync -avz iris-cluster:/home/users/&lt;LOGIN&gt;/PS2/jcell/results .
</code></pre>
<p><strong>Question</strong>: check the system load and memory usage with Ganglia
(<a href="https://hpc.uni.lu/chaos/ganglia">Chaos</a>, <a href="https://hpc.uni.lu/gaia/ganglia">Gaia</a>)</p>
<h2 id="conclusion">Conclusion</h2>
<p><strong>At the end, please clean up your home and work directories :)</strong></p>
<p><strong>Please</strong> do not store unnecessary files on the cluster's storage servers:</p>
<pre><code>(access)$&gt; rm -rf $HOME/PS2
</code></pre>
<p>For going further:</p>
<ul>
<li><a href="http://hpc.uni.lu/users/docs/oar.html#checkpointing">Checkpoint / restart with BLCR</a></li>
<li><a href="http://crimson.oca.eu/spip.php?article157">OAR array jobs (fr)</a></li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../advanced/Debug/" class="btn btn-neutral float-right" title="Efficient Debugging">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../getting_started/" class="btn btn-neutral" title="Getting Started"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../getting_started/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../advanced/Debug/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
